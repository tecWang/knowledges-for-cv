
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [Quick Start (Python API)](#quick-start-python-api)
  - [关键点对应关系](#关键点对应关系)
  - [Python接口中一些重要的属性](#python接口中一些重要的属性)
  - [模型初始化](#模型初始化)
  - [身体躯干关键点检测](#身体躯干关键点检测)
  - [手部检测](#手部检测)
  - [指定预选框的手部检测](#指定预选框的手部检测)

<!-- /code_chunk_output -->

### Quick Start (Python API)

#### 关键点对应关系

poseKeypoints中的行索引与pose25的点位是对应的，直接读取就好

![](./images/openpose-keypoints_pose_25.png)

![](./images/openpose-keypoints_face.png)

![](./images/openpose-keypoints_hand.png)

#### Python接口中一些重要的属性

```cpp
// Datum Object
py::class_<Datum, std::shared_ptr<Datum>>(m, "Datum")
    .def(py::init<>())
    .def_readwrite("id", &Datum::id)
    .def_readwrite("subId", &Datum::subId)
    .def_readwrite("subIdMax", &Datum::subIdMax)
    .def_readwrite("name", &Datum::name)
    .def_readwrite("frameNumber", &Datum::frameNumber)

    // 模型输入
    .def_readwrite("cvInputData", &Datum::cvInputData)  # 
    .def_readwrite("inputNetData", &Datum::inputNetData)

    // 模型输出
    .def_readwrite("outputData", &Datum::outputData)
    .def_readwrite("cvOutputData", &Datum::cvOutputData)
    .def_readwrite("cvOutputData3D", &Datum::cvOutputData3D)

    // 模型检测道德关键点
    .def_readwrite("poseKeypoints", &Datum::poseKeypoints)
    .def_readwrite("poseIds", &Datum::poseIds)
    .def_readwrite("poseScores", &Datum::poseScores)
    .def_readwrite("poseHeatMaps", &Datum::poseHeatMaps)
    .def_readwrite("poseCandidates", &Datum::poseCandidates)

    // 模型的脸部检测预选框
    .def_readwrite("faceRectangles", &Datum::faceRectangles)
    .def_readwrite("faceKeypoints", &Datum::faceKeypoints)
    .def_readwrite("faceHeatMaps", &Datum::faceHeatMaps)

    // 模型的手部检测预选框
    .def_readwrite("handRectangles", &Datum::handRectangles)
    .def_readwrite("handKeypoints", &Datum::handKeypoints)
    .def_readwrite("handHeatMaps", &Datum::handHeatMaps)
    .def_readwrite("poseKeypoints3D", &Datum::poseKeypoints3D)
    .def_readwrite("faceKeypoints3D", &Datum::faceKeypoints3D)
    .def_readwrite("handKeypoints3D", &Datum::handKeypoints3D)
    .def_readwrite("cameraMatrix", &Datum::cameraMatrix)
    .def_readwrite("cameraExtrinsics", &Datum::cameraExtrinsics)
    .def_readwrite("cameraIntrinsics", &Datum::cameraIntrinsics)
    .def_readwrite("poseNetOutput", &Datum::poseNetOutput)
    .def_readwrite("scaleInputToNetInputs", &Datum::scaleInputToNetInputs)
    .def_readwrite("netInputSizes", &Datum::netInputSizes)
    .def_readwrite("scaleInputToOutput", &Datum::scaleInputToOutput)
    .def_readwrite("netOutputSize", &Datum::netOutputSize)
    .def_readwrite("scaleNetToOutput", &Datum::scaleNetToOutput)
    .def_readwrite("elementRendered", &Datum::elementRendered);
```

```cpp
// Rectangle 用来定义脸部或手部预选框
py::class_<Rectangle<float>>(m, "Rectangle")
    .def("__repr__", [](Rectangle<float> &a) { return a.toString(); })
    .def(py::init<>())
    .def(py::init<float, float, float, float>())

    // 即可以用x, y, width, height调用该属性
    .def_readwrite("x", &Rectangle<float>::x)
    .def_readwrite("y", &Rectangle<float>::y)
    .def_readwrite("width", &Rectangle<float>::width)
    .def_readwrite("height", &Rectangle<float>::height);
```

#### 模型初始化

```python
# 模型的初始化可以选择一切从简
# 也可以选择添加手部检测功能等
def start_op(hand_detect=False):
    params = dict()
    params["model_folder"] = "../../../models/"
    if hand_detect:
        params["hand"] = True
        # params["hand_detector"] = 2
    opWrapper = op.WrapperPython()
    opWrapper.configure(params)
    opWrapper.start()
    return opWrapper
```

#### 身体躯干关键点检测

```python
opWrapper = start_op()
datum = op.Datum()
datum.cvInputData = image
opWrapper.emplaceAndPop([datum])
out = datum.cvOutputData
cv2.imshow("image", out)
```

#### 手部检测

与上一个的差别主要就在于op的初始化

```python
opWrapper = start_op(hand_detect=True)
datum = op.Datum()
datum.cvInputData = image
opWrapper.emplaceAndPop([datum])
out = datum.cvOutputData
cv2.imshow("image", out)
```

#### 指定预选框的手部检测

制定预选框可能会有更快的检测速度吧～
可能的应用比如用yolo检测一个大概的坐标直接检测，速度应该会比较快，比较适合于仅仅针对手部的姿态检测

```python
opWrapper = start_op(hand_detect=True)
datum = op.Datum()
datum.cvInputData = image
handRectangles = [
    # Left/Right hands person 0
    [
        op.Rectangle(320.035889, 377.675049, 69.300949, 69.300949),
        op.Rectangle(0., 0., 0., 0.),
    ],
    # Left/Right hands person 1
    [
        op.Rectangle(80.155792, 407.673492, 80.812706, 80.812706),
        op.Rectangle(46.449715, 404.559753, 98.898178, 98.898178),
    ],
    # Left/Right hands person 2
    [
        op.Rectangle(185.692673, 303.112244, 157.587555, 157.587555),
        op.Rectangle(88.984360, 268.866547, 117.818230, 117.818230),
    ]
]
datum.handRectangles = handRectangles
opWrapper.emplaceAndPop([datum])
out = datum.cvOutputData
cv2.imshow("image", out)
```